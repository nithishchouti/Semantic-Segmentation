{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics ptflops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbSKiMABa-WZ",
        "outputId": "0f727020-99fa-49a8-c498-ef68d1ad6644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptflops\n",
            "  Downloading ptflops-0.7.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.3.post0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, ptflops\n",
            "Successfully installed lightning-utilities-0.11.3.post0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ptflops-0.7.3 torchmetrics-1.4.0.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, datasets, transforms\n",
        "from torchvision.models import mobilenet_v2, mobilenet_v3_large, mobilenet_v3_small\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import psutil\n",
        "import torchmetrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Function to get initial GPU memory usage\n",
        "def initial_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()  # Release any existing memory\n",
        "        return torch.cuda.memory_allocated() / (1024 * 1024)  # Convert to MB\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to calculate final GPU memory usage\n",
        "def final_gpu_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.cuda.memory_allocated() / (1024 * 1024)  # Convert to MB\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Function to get GPU power usage\n",
        "def get_gpu_power_usage():\n",
        "    result = subprocess.run(\n",
        "        ['nvidia-smi', '--query-gpu=power.draw', '--format=csv,noheader,nounits'],\n",
        "        stdout=subprocess.PIPE, text=True\n",
        "    )\n",
        "    power_draws = result.stdout.strip().split('\\n')\n",
        "    power_draws = [float(power) for power in power_draws]\n",
        "    return sum(power_draws) / len(power_draws)\n",
        "\n",
        "class VOCSegmentationCustom(datasets.VOCSegmentation):\n",
        "    def __init__(self, root, year='2012', image_set='train', transform=None, target_transform=None, transforms=None):\n",
        "        super(VOCSegmentationCustom, self).__init__(root, year, image_set, transform, target_transform, transforms)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.images[index]).convert('RGB')\n",
        "        target = Image.open(self.masks[index])\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "# Transforms\n",
        "transformer = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "target_transformer = transforms.Compose([\n",
        "    transforms.Resize((224, 224), interpolation=Image.NEAREST),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: torch.squeeze(x, 0).long())\n",
        "])\n",
        "\n",
        "# Initialize custom dataset\n",
        "train_dataset = VOCSegmentationCustom(\n",
        "    root='./data', year='2012', image_set='train', transform=transformer, target_transform=target_transformer)\n",
        "test_dataset = VOCSegmentationCustom(\n",
        "    root='./data', year='2012', image_set='val', transform=transformer, target_transform=target_transformer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "# Custom IntermediateLayerGetter\n",
        "class IntermediateLayerGetter(nn.ModuleDict):\n",
        "    def __init__(self, model, return_layers):\n",
        "        if not set(return_layers).issubset([name for name, _ in model.named_children()]):\n",
        "            raise ValueError(\"return_layers are not present in model\")\n",
        "\n",
        "        orig_return_layers = return_layers\n",
        "        return_layers = {str(k): str(v) for k, v in return_layers.items()}\n",
        "        layers = {k: v for k, v in model.named_children() if k in return_layers}\n",
        "        super(IntermediateLayerGetter, self).__init__(layers)\n",
        "        self.return_layers = orig_return_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = {}\n",
        "        for name, module in self.named_children():\n",
        "            x = module(x)\n",
        "            if name in self.return_layers:\n",
        "                out_name = self.return_layers[name]\n",
        "                out[out_name] = x\n",
        "        return out\n",
        "\n",
        "# ASPP (Atrous Spatial Pyramid Pooling) Module\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, output_stride):\n",
        "        super(ASPP, self).__init__()\n",
        "        self.act = nn.ReLU6()\n",
        "        self.bn_1 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn_2 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn_3 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn_4 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn_5 = nn.BatchNorm2d(out_channels)\n",
        "        self.bn_6 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        if output_stride == 16:\n",
        "            self.operation_1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "            self.operation_2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=6, dilation=6)\n",
        "            self.operation_3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
        "            self.operation_4 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=18, dilation=18)\n",
        "        elif output_stride == 8:\n",
        "            self.operation_1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "            self.operation_2 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=12, dilation=12)\n",
        "            self.operation_3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=24, dilation=24)\n",
        "            self.operation_4 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=36, dilation=36)\n",
        "        else:\n",
        "            raise ValueError('Output stride must be 8 or 16')\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1))\n",
        "        self.conv_pool = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.conv = nn.Conv2d(out_channels * 5, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output_1 = self.act(self.bn_1(self.operation_1(x)))\n",
        "        output_2 = self.act(self.bn_2(self.operation_2(x)))\n",
        "        output_3 = self.act(self.bn_3(self.operation_3(x)))\n",
        "        output_4 = self.act(self.bn_4(self.operation_4(x)))\n",
        "        pool = self.pool(x)\n",
        "        pool = self.act(self.bn_5(self.conv_pool(pool)))\n",
        "        pool = F.interpolate(pool, size=x.size()[2:], mode='bilinear', align_corners=True)\n",
        "        output = torch.cat((output_1, output_2, output_3, output_4, pool), dim=1)\n",
        "        output = self.act(self.bn_6(self.conv(output)))\n",
        "        return output\n",
        "\n",
        "# Deeplab Decoder\n",
        "class Deeplab(nn.Module):\n",
        "    def __init__(self, low_feat_ch, high_feat_ch, num_classes, output_stride):\n",
        "        super(Deeplab, self).__init__()\n",
        "        self.aspp = ASPP(high_feat_ch, 256, output_stride)\n",
        "        self.low_conv = nn.Conv2d(low_feat_ch, 48, kernel_size=1)\n",
        "        self.low_bn = nn.BatchNorm2d(48)\n",
        "        self.act = nn.ReLU6()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Conv2d(304, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, low_features, high_features):\n",
        "        high_features = self.aspp(high_features)\n",
        "        low_features = self.act(self.low_bn(self.low_conv(low_features)))\n",
        "        high_features = F.interpolate(high_features, size=low_features.size()[2:], mode='bilinear', align_corners=True)\n",
        "        concat_features = torch.cat([high_features, low_features], dim=1)\n",
        "        output = self.classifier(concat_features)\n",
        "        return output\n",
        "\n",
        "# Backbone Loader\n",
        "def backbone_loader(model_name):\n",
        "    if model_name == 'mobilenet_v2':\n",
        "        backbone = models.mobilenet_v2(pretrained=True)\n",
        "        low_level_features = backbone.features[:4]\n",
        "        high_level_features = backbone.features[4:-1]\n",
        "        low_feat_ch = 24\n",
        "        high_feat_ch = 320\n",
        "    elif model_name == 'mobilenet_v3_large':\n",
        "        backbone = mobilenet_v3_large(pretrained=True)\n",
        "        low_level_features = backbone.features[:7]\n",
        "        high_level_features = backbone.features[7:]\n",
        "        low_feat_ch = 40\n",
        "        high_feat_ch = 960\n",
        "    elif model_name == 'mobilenet_v3_small':\n",
        "        backbone = mobilenet_v3_small(pretrained=True)\n",
        "        low_level_features = backbone.features[:4]\n",
        "        high_level_features = backbone.features[4:]\n",
        "        low_feat_ch = 24\n",
        "        high_feat_ch = 576  # Adjust based on the backbone architecture\n",
        "\n",
        "    return_layers = {'high_level_features': 'out', 'low_level_features': 'low_level'}\n",
        "    backbone = IntermediateLayerGetter(nn.ModuleDict({'low_level_features': low_level_features, 'high_level_features': high_level_features}), return_layers=return_layers)\n",
        "    return backbone, low_feat_ch, high_feat_ch\n",
        "\n",
        "# Segmentation Model\n",
        "class SegmentationCustom(nn.Module):\n",
        "    def __init__(self, num_classes, output_stride, model_name):\n",
        "        super(SegmentationCustom, self).__init__()\n",
        "        self.feature_extractor, low_feat_ch, high_feat_ch = backbone_loader(model_name)\n",
        "        self.deeplab = Deeplab(low_feat_ch=low_feat_ch, high_feat_ch=high_feat_ch, num_classes=num_classes, output_stride=output_stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "        original_shape = x.shape[2:]\n",
        "        features = self.feature_extractor(x)\n",
        "        output_map = self.deeplab(features['low_level'], features['out'])\n",
        "        output_map = F.interpolate(output_map, size=original_shape, mode='bilinear', align_corners=True)\n",
        "        return output_map\n",
        "\n",
        "# Initialize models\n",
        "mobilenetv2_model = SegmentationCustom(num_classes=21, output_stride=16, model_name='mobilenet_v2')\n",
        "mobilenetv3_large_model = SegmentationCustom(num_classes=21, output_stride=16, model_name='mobilenet_v3_large')\n",
        "mobilenetv3_small_model = SegmentationCustom(num_classes=21, output_stride=16, model_name='mobilenet_v3_small')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    mobilenetv2_model.cuda()\n",
        "    mobilenetv3_large_model.cuda()\n",
        "    mobilenetv3_small_model.cuda()\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_v2 = SGD(mobilenetv2_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "optimizer_v3_large = SGD(mobilenetv3_large_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "optimizer_v3_small = SGD(mobilenetv3_small_model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "# Function to calculate mIoU and PA\n",
        "def calculate_metrics(predictions, labels, num_classes):\n",
        "    iou = torchmetrics.JaccardIndex(task='multiclass', num_classes=num_classes).to(predictions.device)\n",
        "    miou = iou(predictions, labels)\n",
        "\n",
        "    accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes).to(predictions.device)\n",
        "    pa = accuracy(predictions, labels)\n",
        "\n",
        "    return miou, pa\n",
        "\n",
        "# Train and Evaluate function with additional metrics and memory usage\n",
        "def train_and_evaluate(model, optimizer, train_loader, test_loader, epochs=50, save_path=None):\n",
        "\n",
        "    # initial_gpu_mem = initial_gpu_memory()\n",
        "\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    initial_gpu_mem = initial_gpu_memory()\n",
        "    initial_power = get_gpu_power_usage()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch + 1}, Loss: {avg_loss}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    final_power = get_gpu_power_usage()\n",
        "    print(f'Training Time: {end_time - start_time:.2f} seconds')\n",
        "    print(f'Average Power Consumption during Training: {(initial_power + final_power) / 2:.2f} W')\n",
        "\n",
        "    # Save the trained model\n",
        "    if save_path:\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f'Model saved to {save_path}')\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    initial_gpu_mem = initial_gpu_memory()\n",
        "    initial_power = get_gpu_power_usage()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_time = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            start_time = time.time()\n",
        "            outputs = model(inputs)\n",
        "            end_time = time.time()\n",
        "            total_time += (end_time - start_time)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.nelement()\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            all_predictions.append(predicted)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    end_time = time.time()\n",
        "    final_power = get_gpu_power_usage()\n",
        "    print(f'Evaluation Time: {end_time - start_time:.2f} seconds')\n",
        "    print(f'Average Power Consumption during Evaluation: {(initial_power + final_power) / 2:.2f} W')\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = correct / total\n",
        "    avg_inference_time = total_time / len(test_loader)\n",
        "    gpu_mem_usage = final_gpu_memory() - initial_gpu_mem  # Final GPU memory usage\n",
        "\n",
        "    all_predictions = torch.cat(all_predictions)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    miou, pa = calculate_metrics(all_predictions, all_labels, num_classes=21)\n",
        "\n",
        "    return accuracy, avg_inference_time, gpu_mem_usage, miou, pa\n",
        "\n",
        "# Train and evaluate models\n",
        "print(\"Training MobileNetV2...\")\n",
        "metrics_v2 = train_and_evaluate(mobilenetv2_model, optimizer_v2, train_loader, test_loader, save_path='mobilenetv2_model.pth')\n",
        "print(\"Training MobileNetV3 Large...\")\n",
        "metrics_v3_large = train_and_evaluate(mobilenetv3_large_model, optimizer_v3_large, train_loader, test_loader, save_path='mobilenetv3_large_model.pth')\n",
        "print(\"Training MobileNetV3 Small...\")\n",
        "metrics_v3_small = train_and_evaluate(mobilenetv3_small_model, optimizer_v3_small, train_loader, test_loader, save_path='mobilenetv3_small_model.pth')\n",
        "\n",
        "# Print results including memory usage\n",
        "print(f'MobileNetV2 - Accuracy: {metrics_v2[0]}, Inference Time: {metrics_v2[1]}, Final GPU Memory Usage: {metrics_v2[2]} MB, mIoU: {metrics_v2[3]}, Pixel Accuracy: {metrics_v2[4]}')\n",
        "print(f'MobileNetV3 Large - Accuracy: {metrics_v3_large[0]}, Inference Time: {metrics_v3_large[1]}, Final GPU Memory Usage: {metrics_v3_large[2]} MB, mIoU: {metrics_v3_large[3]}, Pixel Accuracy: {metrics_v3_large[4]}')\n",
        "print(f'MobileNetV3 Small - Accuracy: {metrics_v3_small[0]}, Inference Time: {metrics_v3_small[1]}, Final GPU Memory Usage: {metrics_v3_small[2]} MB, mIoU: {metrics_v3_small[3]}, Pixel Accuracy: {metrics_v3_small[4]}')\n"
      ],
      "metadata": {
        "id": "AFne_GzS4HRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191ce249-b35e-490e-f6e1-0437f2091b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to ./data/VOCtrainval_11-May-2012.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1999639040/1999639040 [00:08<00:00, 244497070.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n",
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 168MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 145MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n",
            "100%|██████████| 9.83M/9.83M [00:00<00:00, 140MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MobileNetV2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4977114103278335\n",
            "Epoch 2, Loss: 0.22314808431531297\n",
            "Epoch 3, Loss: 0.20432909162474328\n",
            "Epoch 4, Loss: 0.19756684178600506\n",
            "Epoch 5, Loss: 0.19191396646961875\n",
            "Epoch 6, Loss: 0.18708985810782633\n",
            "Epoch 7, Loss: 0.18285848083747488\n",
            "Epoch 8, Loss: 0.18126241639763319\n",
            "Epoch 9, Loss: 0.179455501540583\n",
            "Epoch 10, Loss: 0.17614381562690345\n",
            "Epoch 11, Loss: 0.17356617520658338\n",
            "Epoch 12, Loss: 0.17257261808429444\n",
            "Epoch 13, Loss: 0.170735413930854\n",
            "Epoch 14, Loss: 0.17043988001184399\n",
            "Epoch 15, Loss: 0.16803126848068367\n",
            "Epoch 16, Loss: 0.16709178589841947\n",
            "Epoch 17, Loss: 0.16609032264574855\n",
            "Epoch 18, Loss: 0.16564019561624851\n",
            "Epoch 19, Loss: 0.1638390339252089\n",
            "Epoch 20, Loss: 0.16324953086116686\n",
            "Epoch 21, Loss: 0.16314644412118562\n",
            "Epoch 22, Loss: 0.16219873559110018\n",
            "Epoch 23, Loss: 0.16212120794114612\n",
            "Epoch 24, Loss: 0.15946678325635236\n",
            "Epoch 25, Loss: 0.15966355162007467\n",
            "Epoch 26, Loss: 0.15939698981590011\n",
            "Epoch 27, Loss: 0.15746194017784937\n",
            "Epoch 28, Loss: 0.1578534082794676\n",
            "Epoch 29, Loss: 0.15736035232235784\n",
            "Epoch 30, Loss: 0.1557824962905475\n",
            "Epoch 31, Loss: 0.15661181494289514\n",
            "Epoch 32, Loss: 0.1554565576671743\n",
            "Epoch 33, Loss: 0.15426676461891253\n",
            "Epoch 34, Loss: 0.15544093709413698\n",
            "Epoch 35, Loss: 0.15557502108771784\n",
            "Epoch 36, Loss: 0.1532120630145073\n",
            "Epoch 37, Loss: 0.1530185172042879\n",
            "Epoch 38, Loss: 0.1518945816118701\n",
            "Epoch 39, Loss: 0.15183894554165756\n",
            "Epoch 40, Loss: 0.15062221783359034\n",
            "Epoch 41, Loss: 0.15101411680177768\n",
            "Epoch 42, Loss: 0.1498136683082094\n",
            "Epoch 43, Loss: 0.15030195239652583\n",
            "Epoch 44, Loss: 0.1496929874529644\n",
            "Epoch 45, Loss: 0.14867613743357108\n",
            "Epoch 46, Loss: 0.14994425843564832\n",
            "Epoch 47, Loss: 0.14826149903998084\n",
            "Epoch 48, Loss: 0.14870359429291316\n",
            "Epoch 49, Loss: 0.1481901245559154\n",
            "Epoch 50, Loss: 0.14766038249747282\n",
            "Training Time: 949.92 seconds\n",
            "Average Power Consumption during Training: 45.92 W\n",
            "Model saved to mobilenetv2_model.pth\n",
            "Evaluation Time: 0.05 seconds\n",
            "Average Power Consumption during Evaluation: 45.95 W\n",
            "Training MobileNetV3 Large...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.464738916377632\n",
            "Epoch 2, Loss: 0.22474534495347212\n",
            "Epoch 3, Loss: 0.2065529067094634\n",
            "Epoch 4, Loss: 0.19984484773103883\n",
            "Epoch 5, Loss: 0.19497506984439836\n",
            "Epoch 6, Loss: 0.19335129000499945\n",
            "Epoch 7, Loss: 0.18864444562164293\n",
            "Epoch 8, Loss: 0.18630787750490668\n",
            "Epoch 9, Loss: 0.183396106522505\n",
            "Epoch 10, Loss: 0.1813302665543394\n",
            "Epoch 11, Loss: 0.17980891699288168\n",
            "Epoch 12, Loss: 0.17718416300355172\n",
            "Epoch 13, Loss: 0.1756835028934641\n",
            "Epoch 14, Loss: 0.17331749139999858\n",
            "Epoch 15, Loss: 0.17168548120325114\n",
            "Epoch 16, Loss: 0.16997396677326995\n",
            "Epoch 17, Loss: 0.1692543362780493\n",
            "Epoch 18, Loss: 0.16728784123651025\n",
            "Epoch 19, Loss: 0.16764896185625167\n",
            "Epoch 20, Loss: 0.1664836503007785\n",
            "Epoch 21, Loss: 0.1655741541766796\n",
            "Epoch 22, Loss: 0.1655617095276612\n",
            "Epoch 23, Loss: 0.16306705129187124\n",
            "Epoch 24, Loss: 0.16274447282966303\n",
            "Epoch 25, Loss: 0.16261317109575077\n",
            "Epoch 26, Loss: 0.161859655512028\n",
            "Epoch 27, Loss: 0.16069733336263772\n",
            "Epoch 28, Loss: 0.16054123077465562\n",
            "Epoch 29, Loss: 0.1599673155923279\n",
            "Epoch 30, Loss: 0.16016349130544533\n",
            "Epoch 31, Loss: 0.15895688462825047\n",
            "Epoch 32, Loss: 0.15789819118522463\n",
            "Epoch 33, Loss: 0.15789168044215157\n",
            "Epoch 34, Loss: 0.1564810168580944\n",
            "Epoch 35, Loss: 0.15665897585096814\n",
            "Epoch 36, Loss: 0.1562777398293521\n",
            "Epoch 37, Loss: 0.15583871360741505\n",
            "Epoch 38, Loss: 0.15509273466609774\n",
            "Epoch 39, Loss: 0.15509582108178108\n",
            "Epoch 40, Loss: 0.15419529353072042\n",
            "Epoch 41, Loss: 0.1539871451400575\n",
            "Epoch 42, Loss: 0.15341400664274385\n",
            "Epoch 43, Loss: 0.15399469643020305\n",
            "Epoch 44, Loss: 0.1525947161170901\n",
            "Epoch 45, Loss: 0.15253609621605904\n",
            "Epoch 46, Loss: 0.15264873900989287\n",
            "Epoch 47, Loss: 0.15141724901539938\n",
            "Epoch 48, Loss: 0.15146300804858304\n",
            "Epoch 49, Loss: 0.15086410600109165\n",
            "Epoch 50, Loss: 0.1504841598422349\n",
            "Training Time: 868.01 seconds\n",
            "Average Power Consumption during Training: 75.12 W\n",
            "Model saved to mobilenetv3_large_model.pth\n",
            "Evaluation Time: 0.06 seconds\n",
            "Average Power Consumption during Evaluation: 39.14 W\n",
            "Training MobileNetV3 Small...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.5017459670297143\n",
            "Epoch 2, Loss: 0.2269545438743773\n",
            "Epoch 3, Loss: 0.2101893483274648\n",
            "Epoch 4, Loss: 0.20235392324575763\n",
            "Epoch 5, Loss: 0.1978967999722682\n",
            "Epoch 6, Loss: 0.19401469922998324\n",
            "Epoch 7, Loss: 0.19190215582953019\n",
            "Epoch 8, Loss: 0.1905807167494378\n",
            "Epoch 9, Loss: 0.18786780191522065\n",
            "Epoch 10, Loss: 0.18639069547255835\n",
            "Epoch 11, Loss: 0.18414665692720283\n",
            "Epoch 12, Loss: 0.18249117719883823\n",
            "Epoch 13, Loss: 0.18163041152110715\n",
            "Epoch 14, Loss: 0.17916157892366655\n",
            "Epoch 15, Loss: 0.17904339097186822\n",
            "Epoch 16, Loss: 0.17763850903835426\n",
            "Epoch 17, Loss: 0.17791026496157356\n",
            "Epoch 18, Loss: 0.17567496645410044\n",
            "Epoch 19, Loss: 0.17599069768068742\n",
            "Epoch 20, Loss: 0.17374646009839312\n",
            "Epoch 21, Loss: 0.17367673949116752\n",
            "Epoch 22, Loss: 0.17370940871587415\n",
            "Epoch 23, Loss: 0.17263982429796335\n",
            "Epoch 24, Loss: 0.17101545454490752\n",
            "Epoch 25, Loss: 0.17073241991250693\n",
            "Epoch 26, Loss: 0.1690044801960997\n",
            "Epoch 27, Loss: 0.16979936576213966\n",
            "Epoch 28, Loss: 0.16787661956686553\n",
            "Epoch 29, Loss: 0.1666874039639421\n",
            "Epoch 30, Loss: 0.16663262227765557\n",
            "Epoch 31, Loss: 0.164714503095669\n",
            "Epoch 32, Loss: 0.1655708727787952\n",
            "Epoch 33, Loss: 0.16576311544698924\n",
            "Epoch 34, Loss: 0.16460820652392447\n",
            "Epoch 35, Loss: 0.16298755167090162\n",
            "Epoch 36, Loss: 0.16322278130013926\n",
            "Epoch 37, Loss: 0.1632842325231656\n",
            "Epoch 38, Loss: 0.16242921813612893\n",
            "Epoch 39, Loss: 0.1615485687341009\n",
            "Epoch 40, Loss: 0.1617288239756409\n",
            "Epoch 41, Loss: 0.16051194821896198\n",
            "Epoch 42, Loss: 0.16093009791406646\n",
            "Epoch 43, Loss: 0.15998464199353238\n",
            "Epoch 44, Loss: 0.15892712908739948\n",
            "Epoch 45, Loss: 0.15867576403479997\n",
            "Epoch 46, Loss: 0.15891818986052558\n",
            "Epoch 47, Loss: 0.15759076978884587\n",
            "Epoch 48, Loss: 0.1578188049955433\n",
            "Epoch 49, Loss: 0.1579606351094181\n",
            "Epoch 50, Loss: 0.15775236284651725\n",
            "Training Time: 779.97 seconds\n",
            "Average Power Consumption during Training: 56.42 W\n",
            "Model saved to mobilenetv3_small_model.pth\n",
            "Evaluation Time: 0.06 seconds\n",
            "Average Power Consumption during Evaluation: 34.05 W\n",
            "MobileNetV2 - Accuracy: 0.9438301127580949, Inference Time: 0.009066333441898741, Final GPU Memory Usage: 1136.03955078125 MB, mIoU: 0.47668153047561646, Pixel Accuracy: 0.943830132484436\n",
            "MobileNetV3 Large - Accuracy: 0.9440281045777524, Inference Time: 0.010248998115802634, Final GPU Memory Usage: 1135.54296875 MB, mIoU: 0.4751838445663452, Pixel Accuracy: 0.9440280795097351\n",
            "MobileNetV3 Small - Accuracy: 0.9439761686895255, Inference Time: 0.00911919824008284, Final GPU Memory Usage: 1135.68359375 MB, mIoU: 0.47600650787353516, Pixel Accuracy: 0.9439761638641357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "model_path = 'mobilenetv3_small_model.pth'\n",
        "model = SegmentationCustom(num_classes=21, output_stride=16, model_name='mobilenet_v3_small')\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total trainable parameters: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfhPNUSJuDh7",
        "outputId": "3b78aa63-f73a-40fa-e261-3d6fb1e198a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total trainable parameters: 6243397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "model = SegmentationCustom(num_classes=21, output_stride=16, model_name='mobilenet_v2')\n",
        "\n",
        "# Set input resolution (adjust as needed)\n",
        "input_res = (3, 224, 224)\n",
        "\n",
        "# Calculate FLOPs and parameters\n",
        "macs, params = get_model_complexity_info(model, input_res, as_strings=True,\n",
        "                                           print_per_layer_stat=True, verbose=True)\n",
        "\n",
        "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
        "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74V1SZwyuePu",
        "outputId": "3954fef6-7d52-4ee9-ff33-2a9efee6670f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: module Conv2dNormActivation is treated as a zero-op.\n",
            "Warning: module InvertedResidual is treated as a zero-op.\n",
            "Warning: module IntermediateLayerGetter is treated as a zero-op.\n",
            "Warning: module ASPP is treated as a zero-op.\n",
            "Warning: module Deeplab is treated as a zero-op.\n",
            "Warning: module SegmentationCustom is treated as a zero-op.\n",
            "SegmentationCustom(\n",
            "  5.23 M, 100.000% Params, 2.65 GMac, 99.967% MACs, \n",
            "  (feature_extractor): IntermediateLayerGetter(\n",
            "    1.81 M, 34.657% Params, 298.7 MMac, 11.275% MACs, \n",
            "    (low_level_features): Sequential(\n",
            "      15.79 k, 0.302% Params, 86.15 MMac, 3.252% MACs, \n",
            "      (0): Conv2dNormActivation(\n",
            "        928, 0.018% Params, 12.04 MMac, 0.455% MACs, \n",
            "        (0): Conv2d(864, 0.017% Params, 10.84 MMac, 0.409% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(64, 0.001% Params, 802.82 KMac, 0.030% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU6(0, 0.000% Params, 401.41 KMac, 0.015% MACs, inplace=True)\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        896, 0.017% Params, 11.64 MMac, 0.439% MACs, \n",
            "        (conv): Sequential(\n",
            "          896, 0.017% Params, 11.64 MMac, 0.439% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            352, 0.007% Params, 4.82 MMac, 0.182% MACs, \n",
            "            (0): Conv2d(288, 0.006% Params, 3.61 MMac, 0.136% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "            (1): BatchNorm2d(64, 0.001% Params, 802.82 KMac, 0.030% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 401.41 KMac, 0.015% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2d(512, 0.010% Params, 6.42 MMac, 0.242% MACs, 32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(32, 0.001% Params, 401.41 KMac, 0.015% MACs, 16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        5.14 k, 0.098% Params, 33.87 MMac, 1.278% MACs, \n",
            "        (conv): Sequential(\n",
            "          5.14 k, 0.098% Params, 33.87 MMac, 1.278% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            1.73 k, 0.033% Params, 22.88 MMac, 0.864% MACs, \n",
            "            (0): Conv2d(1.54 k, 0.029% Params, 19.27 MMac, 0.727% MACs, 16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, 0.004% Params, 2.41 MMac, 0.091% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 1.2 MMac, 0.045% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            1.06 k, 0.020% Params, 3.61 MMac, 0.136% MACs, \n",
            "            (0): Conv2d(864, 0.017% Params, 2.71 MMac, 0.102% MACs, 96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
            "            (1): BatchNorm2d(192, 0.004% Params, 602.11 KMac, 0.023% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 301.06 KMac, 0.011% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(2.3 k, 0.044% Params, 7.23 MMac, 0.273% MACs, 96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(48, 0.001% Params, 150.53 KMac, 0.006% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (3): InvertedResidual(\n",
            "        8.83 k, 0.169% Params, 28.6 MMac, 1.080% MACs, \n",
            "        (conv): Sequential(\n",
            "          8.83 k, 0.169% Params, 28.6 MMac, 1.080% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            3.74 k, 0.072% Params, 12.19 MMac, 0.460% MACs, \n",
            "            (0): Conv2d(3.46 k, 0.066% Params, 10.84 MMac, 0.409% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(288, 0.006% Params, 903.17 KMac, 0.034% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 451.58 KMac, 0.017% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            1.58 k, 0.030% Params, 5.42 MMac, 0.205% MACs, \n",
            "            (0): Conv2d(1.3 k, 0.025% Params, 4.06 MMac, 0.153% MACs, 144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(288, 0.006% Params, 903.17 KMac, 0.034% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 451.58 KMac, 0.017% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(3.46 k, 0.066% Params, 10.84 MMac, 0.409% MACs, 144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(48, 0.001% Params, 150.53 KMac, 0.006% MACs, 24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (high_level_features): Sequential(\n",
            "      1.8 M, 34.355% Params, 212.55 MMac, 8.023% MACs, \n",
            "      (4): InvertedResidual(\n",
            "        10.0 k, 0.191% Params, 17.21 MMac, 0.650% MACs, \n",
            "        (conv): Sequential(\n",
            "          10.0 k, 0.191% Params, 17.21 MMac, 0.650% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            3.74 k, 0.072% Params, 12.19 MMac, 0.460% MACs, \n",
            "            (0): Conv2d(3.46 k, 0.066% Params, 10.84 MMac, 0.409% MACs, 24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(288, 0.006% Params, 903.17 KMac, 0.034% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 451.58 KMac, 0.017% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            1.58 k, 0.030% Params, 1.35 MMac, 0.051% MACs, \n",
            "            (0): Conv2d(1.3 k, 0.025% Params, 1.02 MMac, 0.038% MACs, 144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(288, 0.006% Params, 225.79 KMac, 0.009% MACs, 144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 112.9 KMac, 0.004% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(4.61 k, 0.088% Params, 3.61 MMac, 0.136% MACs, 144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, 0.001% Params, 50.18 KMac, 0.002% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (5): InvertedResidual(\n",
            "        14.85 k, 0.284% Params, 11.94 MMac, 0.451% MACs, \n",
            "        (conv): Sequential(\n",
            "          14.85 k, 0.284% Params, 11.94 MMac, 0.451% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            6.53 k, 0.125% Params, 5.27 MMac, 0.199% MACs, \n",
            "            (0): Conv2d(6.14 k, 0.118% Params, 4.82 MMac, 0.182% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, 0.007% Params, 301.06 KMac, 0.011% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 150.53 KMac, 0.006% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            2.11 k, 0.040% Params, 1.81 MMac, 0.068% MACs, \n",
            "            (0): Conv2d(1.73 k, 0.033% Params, 1.35 MMac, 0.051% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(384, 0.007% Params, 301.06 KMac, 0.011% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 150.53 KMac, 0.006% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(6.14 k, 0.118% Params, 4.82 MMac, 0.182% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, 0.001% Params, 50.18 KMac, 0.002% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (6): InvertedResidual(\n",
            "        14.85 k, 0.284% Params, 11.94 MMac, 0.451% MACs, \n",
            "        (conv): Sequential(\n",
            "          14.85 k, 0.284% Params, 11.94 MMac, 0.451% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            6.53 k, 0.125% Params, 5.27 MMac, 0.199% MACs, \n",
            "            (0): Conv2d(6.14 k, 0.118% Params, 4.82 MMac, 0.182% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, 0.007% Params, 301.06 KMac, 0.011% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 150.53 KMac, 0.006% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            2.11 k, 0.040% Params, 1.81 MMac, 0.068% MACs, \n",
            "            (0): Conv2d(1.73 k, 0.033% Params, 1.35 MMac, 0.051% MACs, 192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(384, 0.007% Params, 301.06 KMac, 0.011% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 150.53 KMac, 0.006% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(6.14 k, 0.118% Params, 4.82 MMac, 0.182% MACs, 192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(64, 0.001% Params, 50.18 KMac, 0.002% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (7): InvertedResidual(\n",
            "        21.06 k, 0.403% Params, 8.15 MMac, 0.308% MACs, \n",
            "        (conv): Sequential(\n",
            "          21.06 k, 0.403% Params, 8.15 MMac, 0.308% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            6.53 k, 0.125% Params, 5.27 MMac, 0.199% MACs, \n",
            "            (0): Conv2d(6.14 k, 0.118% Params, 4.82 MMac, 0.182% MACs, 32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(384, 0.007% Params, 301.06 KMac, 0.011% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 150.53 KMac, 0.006% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            2.11 k, 0.040% Params, 451.58 KMac, 0.017% MACs, \n",
            "            (0): Conv2d(1.73 k, 0.033% Params, 338.69 KMac, 0.013% MACs, 192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
            "            (1): BatchNorm2d(384, 0.007% Params, 75.26 KMac, 0.003% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 37.63 KMac, 0.001% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(12.29 k, 0.235% Params, 2.41 MMac, 0.091% MACs, 192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, 0.002% Params, 25.09 KMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (8): InvertedResidual(\n",
            "        54.27 k, 1.038% Params, 10.79 MMac, 0.407% MACs, \n",
            "        (conv): Sequential(\n",
            "          54.27 k, 1.038% Params, 10.79 MMac, 0.407% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            25.34 k, 0.485% Params, 5.04 MMac, 0.190% MACs, \n",
            "            (0): Conv2d(24.58 k, 0.470% Params, 4.82 MMac, 0.182% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(768, 0.015% Params, 150.53 KMac, 0.006% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 75.26 KMac, 0.003% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            4.22 k, 0.081% Params, 903.17 KMac, 0.034% MACs, \n",
            "            (0): Conv2d(3.46 k, 0.066% Params, 677.38 KMac, 0.026% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(768, 0.015% Params, 150.53 KMac, 0.006% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 75.26 KMac, 0.003% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(24.58 k, 0.470% Params, 4.82 MMac, 0.182% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, 0.002% Params, 25.09 KMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (9): InvertedResidual(\n",
            "        54.27 k, 1.038% Params, 10.79 MMac, 0.407% MACs, \n",
            "        (conv): Sequential(\n",
            "          54.27 k, 1.038% Params, 10.79 MMac, 0.407% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            25.34 k, 0.485% Params, 5.04 MMac, 0.190% MACs, \n",
            "            (0): Conv2d(24.58 k, 0.470% Params, 4.82 MMac, 0.182% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(768, 0.015% Params, 150.53 KMac, 0.006% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 75.26 KMac, 0.003% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            4.22 k, 0.081% Params, 903.17 KMac, 0.034% MACs, \n",
            "            (0): Conv2d(3.46 k, 0.066% Params, 677.38 KMac, 0.026% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(768, 0.015% Params, 150.53 KMac, 0.006% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 75.26 KMac, 0.003% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(24.58 k, 0.470% Params, 4.82 MMac, 0.182% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, 0.002% Params, 25.09 KMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (10): InvertedResidual(\n",
            "        54.27 k, 1.038% Params, 10.79 MMac, 0.407% MACs, \n",
            "        (conv): Sequential(\n",
            "          54.27 k, 1.038% Params, 10.79 MMac, 0.407% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            25.34 k, 0.485% Params, 5.04 MMac, 0.190% MACs, \n",
            "            (0): Conv2d(24.58 k, 0.470% Params, 4.82 MMac, 0.182% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(768, 0.015% Params, 150.53 KMac, 0.006% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 75.26 KMac, 0.003% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            4.22 k, 0.081% Params, 903.17 KMac, 0.034% MACs, \n",
            "            (0): Conv2d(3.46 k, 0.066% Params, 677.38 KMac, 0.026% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(768, 0.015% Params, 150.53 KMac, 0.006% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 75.26 KMac, 0.003% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(24.58 k, 0.470% Params, 4.82 MMac, 0.182% MACs, 384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(128, 0.002% Params, 25.09 KMac, 0.001% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (11): InvertedResidual(\n",
            "        66.62 k, 1.274% Params, 13.21 MMac, 0.499% MACs, \n",
            "        (conv): Sequential(\n",
            "          66.62 k, 1.274% Params, 13.21 MMac, 0.499% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            25.34 k, 0.485% Params, 5.04 MMac, 0.190% MACs, \n",
            "            (0): Conv2d(24.58 k, 0.470% Params, 4.82 MMac, 0.182% MACs, 64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(768, 0.015% Params, 150.53 KMac, 0.006% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 75.26 KMac, 0.003% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            4.22 k, 0.081% Params, 903.17 KMac, 0.034% MACs, \n",
            "            (0): Conv2d(3.46 k, 0.066% Params, 677.38 KMac, 0.026% MACs, 384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
            "            (1): BatchNorm2d(768, 0.015% Params, 150.53 KMac, 0.006% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 75.26 KMac, 0.003% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(36.86 k, 0.705% Params, 7.23 MMac, 0.273% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(192, 0.004% Params, 37.63 KMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (12): InvertedResidual(\n",
            "        118.27 k, 2.262% Params, 23.41 MMac, 0.884% MACs, \n",
            "        (conv): Sequential(\n",
            "          118.27 k, 2.262% Params, 23.41 MMac, 0.884% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            56.45 k, 1.080% Params, 11.18 MMac, 0.422% MACs, \n",
            "            (0): Conv2d(55.3 k, 1.058% Params, 10.84 MMac, 0.409% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.022% Params, 225.79 KMac, 0.009% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 112.9 KMac, 0.004% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            6.34 k, 0.121% Params, 1.35 MMac, 0.051% MACs, \n",
            "            (0): Conv2d(5.18 k, 0.099% Params, 1.02 MMac, 0.038% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.022% Params, 225.79 KMac, 0.009% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 112.9 KMac, 0.004% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(55.3 k, 1.058% Params, 10.84 MMac, 0.409% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(192, 0.004% Params, 37.63 KMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (13): InvertedResidual(\n",
            "        118.27 k, 2.262% Params, 23.41 MMac, 0.884% MACs, \n",
            "        (conv): Sequential(\n",
            "          118.27 k, 2.262% Params, 23.41 MMac, 0.884% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            56.45 k, 1.080% Params, 11.18 MMac, 0.422% MACs, \n",
            "            (0): Conv2d(55.3 k, 1.058% Params, 10.84 MMac, 0.409% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.022% Params, 225.79 KMac, 0.009% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 112.9 KMac, 0.004% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            6.34 k, 0.121% Params, 1.35 MMac, 0.051% MACs, \n",
            "            (0): Conv2d(5.18 k, 0.099% Params, 1.02 MMac, 0.038% MACs, 576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.022% Params, 225.79 KMac, 0.009% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 112.9 KMac, 0.004% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(55.3 k, 1.058% Params, 10.84 MMac, 0.409% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(192, 0.004% Params, 37.63 KMac, 0.001% MACs, 96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (14): InvertedResidual(\n",
            "        155.26 k, 2.970% Params, 16.05 MMac, 0.606% MACs, \n",
            "        (conv): Sequential(\n",
            "          155.26 k, 2.970% Params, 16.05 MMac, 0.606% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            56.45 k, 1.080% Params, 11.18 MMac, 0.422% MACs, \n",
            "            (0): Conv2d(55.3 k, 1.058% Params, 10.84 MMac, 0.409% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.022% Params, 225.79 KMac, 0.009% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 112.9 KMac, 0.004% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            6.34 k, 0.121% Params, 338.69 KMac, 0.013% MACs, \n",
            "            (0): Conv2d(5.18 k, 0.099% Params, 254.02 KMac, 0.010% MACs, 576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.022% Params, 56.45 KMac, 0.002% MACs, 576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 28.22 KMac, 0.001% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(92.16 k, 1.763% Params, 4.52 MMac, 0.170% MACs, 576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(320, 0.006% Params, 15.68 KMac, 0.001% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (15): InvertedResidual(\n",
            "        320.0 k, 6.121% Params, 15.77 MMac, 0.595% MACs, \n",
            "        (conv): Sequential(\n",
            "          320.0 k, 6.121% Params, 15.77 MMac, 0.595% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            155.52 k, 2.975% Params, 7.67 MMac, 0.289% MACs, \n",
            "            (0): Conv2d(153.6 k, 2.938% Params, 7.53 MMac, 0.284% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.037% Params, 94.08 KMac, 0.004% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 47.04 KMac, 0.002% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            10.56 k, 0.202% Params, 564.48 KMac, 0.021% MACs, \n",
            "            (0): Conv2d(8.64 k, 0.165% Params, 423.36 KMac, 0.016% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.037% Params, 94.08 KMac, 0.004% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 47.04 KMac, 0.002% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(153.6 k, 2.938% Params, 7.53 MMac, 0.284% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(320, 0.006% Params, 15.68 KMac, 0.001% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (16): InvertedResidual(\n",
            "        320.0 k, 6.121% Params, 15.77 MMac, 0.595% MACs, \n",
            "        (conv): Sequential(\n",
            "          320.0 k, 6.121% Params, 15.77 MMac, 0.595% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            155.52 k, 2.975% Params, 7.67 MMac, 0.289% MACs, \n",
            "            (0): Conv2d(153.6 k, 2.938% Params, 7.53 MMac, 0.284% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.037% Params, 94.08 KMac, 0.004% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 47.04 KMac, 0.002% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            10.56 k, 0.202% Params, 564.48 KMac, 0.021% MACs, \n",
            "            (0): Conv2d(8.64 k, 0.165% Params, 423.36 KMac, 0.016% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.037% Params, 94.08 KMac, 0.004% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 47.04 KMac, 0.002% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(153.6 k, 2.938% Params, 7.53 MMac, 0.284% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(320, 0.006% Params, 15.68 KMac, 0.001% MACs, 160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (17): InvertedResidual(\n",
            "        473.92 k, 9.066% Params, 23.32 MMac, 0.880% MACs, \n",
            "        (conv): Sequential(\n",
            "          473.92 k, 9.066% Params, 23.32 MMac, 0.880% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            155.52 k, 2.975% Params, 7.67 MMac, 0.289% MACs, \n",
            "            (0): Conv2d(153.6 k, 2.938% Params, 7.53 MMac, 0.284% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.037% Params, 94.08 KMac, 0.004% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 47.04 KMac, 0.002% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            10.56 k, 0.202% Params, 564.48 KMac, 0.021% MACs, \n",
            "            (0): Conv2d(8.64 k, 0.165% Params, 423.36 KMac, 0.016% MACs, 960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.037% Params, 94.08 KMac, 0.004% MACs, 960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU6(0, 0.000% Params, 47.04 KMac, 0.002% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2d(307.2 k, 5.877% Params, 15.05 MMac, 0.568% MACs, 960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): BatchNorm2d(640, 0.012% Params, 31.36 KMac, 0.001% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (deeplab): Deeplab(\n",
            "    3.42 M, 65.343% Params, 2.35 GMac, 88.692% MACs, \n",
            "    (aspp): ASPP(\n",
            "      2.71 M, 51.802% Params, 128.8 MMac, 4.862% MACs, \n",
            "      (act): ReLU6(0, 0.000% Params, 62.98 KMac, 0.002% MACs, )\n",
            "      (bn_1): BatchNorm2d(512, 0.010% Params, 25.09 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_2): BatchNorm2d(512, 0.010% Params, 25.09 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_3): BatchNorm2d(512, 0.010% Params, 25.09 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_4): BatchNorm2d(512, 0.010% Params, 25.09 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_5): BatchNorm2d(512, 0.010% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_6): BatchNorm2d(512, 0.010% Params, 25.09 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (operation_1): Conv2d(82.18 k, 1.572% Params, 4.03 MMac, 0.152% MACs, 320, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (operation_2): Conv2d(737.54 k, 14.109% Params, 36.14 MMac, 1.364% MACs, 320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "      (operation_3): Conv2d(737.54 k, 14.109% Params, 36.14 MMac, 1.364% MACs, 320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
            "      (operation_4): Conv2d(737.54 k, 14.109% Params, 36.14 MMac, 1.364% MACs, 320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
            "      (pool): AdaptiveAvgPool2d(0, 0.000% Params, 15.68 KMac, 0.001% MACs, output_size=1)\n",
            "      (conv_pool): Conv2d(82.18 k, 1.572% Params, 82.18 KMac, 0.003% MACs, 320, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv): Conv2d(327.94 k, 6.273% Params, 16.07 MMac, 0.607% MACs, 1280, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (low_conv): Conv2d(1.2 k, 0.023% Params, 3.76 MMac, 0.142% MACs, 24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (low_bn): BatchNorm2d(96, 0.002% Params, 301.06 KMac, 0.011% MACs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (act): ReLU6(0, 0.000% Params, 150.53 KMac, 0.006% MACs, )\n",
            "    (classifier): Sequential(\n",
            "      706.58 k, 13.516% Params, 2.22 GMac, 83.671% MACs, \n",
            "      (0): Conv2d(700.67 k, 13.403% Params, 2.2 GMac, 82.942% MACs, 304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, 0.010% Params, 1.61 MMac, 0.061% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(0, 0.000% Params, 802.82 KMac, 0.030% MACs, inplace=True)\n",
            "      (3): Conv2d(5.4 k, 0.103% Params, 16.92 MMac, 0.639% MACs, 256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Computational complexity:       2.65 GMac\n",
            "Number of parameters:           5.23 M  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "model = SegmentationCustom(num_classes=21, output_stride=16, model_name='mobilenet_v3_large')\n",
        "\n",
        "# Set input resolution (adjust as needed)\n",
        "input_res = (3, 224, 224)\n",
        "\n",
        "# Calculate FLOPs and parameters\n",
        "macs, params = get_model_complexity_info(model, input_res, as_strings=True,\n",
        "                                           print_per_layer_stat=True, verbose=True)\n",
        "\n",
        "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
        "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imsm4c2TuIgQ",
        "outputId": "cf6a6c26-628e-4e26-fb89-7d4dce930e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ptflops\n",
            "  Downloading ptflops-0.7.3-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->ptflops) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->ptflops) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ptflops) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ptflops) (1.3.0)\n",
            "Installing collected packages: ptflops\n",
            "Successfully installed ptflops-0.7.3\n",
            "Warning: module Hardswish is treated as a zero-op.\n",
            "Warning: module Conv2dNormActivation is treated as a zero-op.\n",
            "Warning: module InvertedResidual is treated as a zero-op.\n",
            "Warning: module Hardsigmoid is treated as a zero-op.\n",
            "Warning: module SqueezeExcitation is treated as a zero-op.\n",
            "Warning: module IntermediateLayerGetter is treated as a zero-op.\n",
            "Warning: module ASPP is treated as a zero-op.\n",
            "Warning: module Deeplab is treated as a zero-op.\n",
            "Warning: module SegmentationCustom is treated as a zero-op.\n",
            "SegmentationCustom(\n",
            "  11.14 M, 100.000% Params, 1.14 GMac, 99.718% MACs, \n",
            "  (feature_extractor): IntermediateLayerGetter(\n",
            "    2.97 M, 26.678% Params, 225.8 MMac, 19.831% MACs, \n",
            "    (low_level_features): Sequential(\n",
            "      61.12 k, 0.549% Params, 80.12 MMac, 7.037% MACs, \n",
            "      (0): Conv2dNormActivation(\n",
            "        464, 0.004% Params, 5.82 MMac, 0.511% MACs, \n",
            "        (0): Conv2d(432, 0.004% Params, 5.42 MMac, 0.476% MACs, 3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(32, 0.000% Params, 401.41 KMac, 0.035% MACs, 16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        464, 0.004% Params, 6.02 MMac, 0.529% MACs, \n",
            "        (block): Sequential(\n",
            "          464, 0.004% Params, 6.02 MMac, 0.529% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            176, 0.002% Params, 2.41 MMac, 0.212% MACs, \n",
            "            (0): Conv2d(144, 0.001% Params, 1.81 MMac, 0.159% MACs, 16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
            "            (1): BatchNorm2d(32, 0.000% Params, 401.41 KMac, 0.035% MACs, 16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 200.7 KMac, 0.018% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            288, 0.003% Params, 3.61 MMac, 0.317% MACs, \n",
            "            (0): Conv2d(256, 0.002% Params, 3.21 MMac, 0.282% MACs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, 0.000% Params, 401.41 KMac, 0.035% MACs, 16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        3.44 k, 0.031% Params, 22.63 MMac, 1.987% MACs, \n",
            "        (block): Sequential(\n",
            "          3.44 k, 0.031% Params, 22.63 MMac, 1.987% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            1.15 k, 0.010% Params, 15.25 MMac, 1.340% MACs, \n",
            "            (0): Conv2d(1.02 k, 0.009% Params, 12.85 MMac, 1.128% MACs, 16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.141% MACs, 64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 802.82 KMac, 0.071% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            704, 0.006% Params, 2.41 MMac, 0.212% MACs, \n",
            "            (0): Conv2d(576, 0.005% Params, 1.81 MMac, 0.159% MACs, 64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "            (1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.035% MACs, 64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 200.7 KMac, 0.018% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            1.58 k, 0.014% Params, 4.97 MMac, 0.436% MACs, \n",
            "            (0): Conv2d(1.54 k, 0.014% Params, 4.82 MMac, 0.423% MACs, 64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, 0.000% Params, 150.53 KMac, 0.013% MACs, 24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): InvertedResidual(\n",
            "        4.44 k, 0.040% Params, 14.38 MMac, 1.263% MACs, \n",
            "        (block): Sequential(\n",
            "          4.44 k, 0.040% Params, 14.38 MMac, 1.263% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            1.87 k, 0.017% Params, 6.1 MMac, 0.535% MACs, \n",
            "            (0): Conv2d(1.73 k, 0.016% Params, 5.42 MMac, 0.476% MACs, 24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, 0.001% Params, 451.58 KMac, 0.040% MACs, 72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 225.79 KMac, 0.020% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            792, 0.007% Params, 2.71 MMac, 0.238% MACs, \n",
            "            (0): Conv2d(648, 0.006% Params, 2.03 MMac, 0.178% MACs, 72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
            "            (1): BatchNorm2d(144, 0.001% Params, 451.58 KMac, 0.040% MACs, 72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 225.79 KMac, 0.020% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            1.78 k, 0.016% Params, 5.57 MMac, 0.489% MACs, \n",
            "            (0): Conv2d(1.73 k, 0.016% Params, 5.42 MMac, 0.476% MACs, 72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, 0.000% Params, 150.53 KMac, 0.013% MACs, 24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): InvertedResidual(\n",
            "        10.33 k, 0.093% Params, 10.06 MMac, 0.883% MACs, \n",
            "        (block): Sequential(\n",
            "          10.33 k, 0.093% Params, 10.06 MMac, 0.883% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            1.87 k, 0.017% Params, 6.1 MMac, 0.535% MACs, \n",
            "            (0): Conv2d(1.73 k, 0.016% Params, 5.42 MMac, 0.476% MACs, 24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, 0.001% Params, 451.58 KMac, 0.040% MACs, 72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 225.79 KMac, 0.020% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            1.94 k, 0.017% Params, 1.58 MMac, 0.139% MACs, \n",
            "            (0): Conv2d(1.8 k, 0.016% Params, 1.41 MMac, 0.124% MACs, 72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
            "            (1): BatchNorm2d(144, 0.001% Params, 112.9 KMac, 0.010% MACs, 72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 56.45 KMac, 0.005% MACs, inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            3.55 k, 0.032% Params, 60.02 KMac, 0.005% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 56.45 KMac, 0.005% MACs, output_size=1)\n",
            "            (fc1): Conv2d(1.75 k, 0.016% Params, 1.75 KMac, 0.000% MACs, 72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(1.8 k, 0.016% Params, 1.8 KMac, 0.000% MACs, 24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 24.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            2.96 k, 0.027% Params, 2.32 MMac, 0.204% MACs, \n",
            "            (0): Conv2d(2.88 k, 0.026% Params, 2.26 MMac, 0.198% MACs, 72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, 0.001% Params, 62.72 KMac, 0.006% MACs, 40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): InvertedResidual(\n",
            "        20.99 k, 0.188% Params, 10.61 MMac, 0.932% MACs, \n",
            "        (block): Sequential(\n",
            "          20.99 k, 0.188% Params, 10.61 MMac, 0.932% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            5.04 k, 0.045% Params, 4.05 MMac, 0.355% MACs, \n",
            "            (0): Conv2d(4.8 k, 0.043% Params, 3.76 MMac, 0.331% MACs, 40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(240, 0.002% Params, 188.16 KMac, 0.017% MACs, 120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 94.08 KMac, 0.008% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            3.24 k, 0.029% Params, 2.63 MMac, 0.231% MACs, \n",
            "            (0): Conv2d(3.0 k, 0.027% Params, 2.35 MMac, 0.207% MACs, 120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "            (1): BatchNorm2d(240, 0.002% Params, 188.16 KMac, 0.017% MACs, 120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 94.08 KMac, 0.008% MACs, inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            7.83 k, 0.070% Params, 101.94 KMac, 0.009% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 94.08 KMac, 0.008% MACs, output_size=1)\n",
            "            (fc1): Conv2d(3.87 k, 0.035% Params, 3.87 KMac, 0.000% MACs, 120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(3.96 k, 0.036% Params, 3.96 KMac, 0.000% MACs, 32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 32.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            4.88 k, 0.044% Params, 3.83 MMac, 0.336% MACs, \n",
            "            (0): Conv2d(4.8 k, 0.043% Params, 3.76 MMac, 0.331% MACs, 120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, 0.001% Params, 62.72 KMac, 0.006% MACs, 40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (6): InvertedResidual(\n",
            "        20.99 k, 0.188% Params, 10.61 MMac, 0.932% MACs, \n",
            "        (block): Sequential(\n",
            "          20.99 k, 0.188% Params, 10.61 MMac, 0.932% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            5.04 k, 0.045% Params, 4.05 MMac, 0.355% MACs, \n",
            "            (0): Conv2d(4.8 k, 0.043% Params, 3.76 MMac, 0.331% MACs, 40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(240, 0.002% Params, 188.16 KMac, 0.017% MACs, 120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 94.08 KMac, 0.008% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            3.24 k, 0.029% Params, 2.63 MMac, 0.231% MACs, \n",
            "            (0): Conv2d(3.0 k, 0.027% Params, 2.35 MMac, 0.207% MACs, 120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "            (1): BatchNorm2d(240, 0.002% Params, 188.16 KMac, 0.017% MACs, 120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 94.08 KMac, 0.008% MACs, inplace=True)\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            7.83 k, 0.070% Params, 101.94 KMac, 0.009% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 94.08 KMac, 0.008% MACs, output_size=1)\n",
            "            (fc1): Conv2d(3.87 k, 0.035% Params, 3.87 KMac, 0.000% MACs, 120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(3.96 k, 0.036% Params, 3.96 KMac, 0.000% MACs, 32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 32.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            4.88 k, 0.044% Params, 3.83 MMac, 0.336% MACs, \n",
            "            (0): Conv2d(4.8 k, 0.043% Params, 3.76 MMac, 0.331% MACs, 120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, 0.001% Params, 62.72 KMac, 0.006% MACs, 40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (high_level_features): Sequential(\n",
            "      2.91 M, 26.130% Params, 145.68 MMac, 12.795% MACs, \n",
            "      (7): InvertedResidual(\n",
            "        32.08 k, 0.288% Params, 12.21 MMac, 1.073% MACs, \n",
            "        (block): Sequential(\n",
            "          32.08 k, 0.288% Params, 12.21 MMac, 1.073% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            10.08 k, 0.090% Params, 7.9 MMac, 0.694% MACs, \n",
            "            (0): Conv2d(9.6 k, 0.086% Params, 7.53 MMac, 0.661% MACs, 40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(480, 0.004% Params, 376.32 KMac, 0.033% MACs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            2.64 k, 0.024% Params, 517.44 KMac, 0.045% MACs, \n",
            "            (0): Conv2d(2.16 k, 0.019% Params, 423.36 KMac, 0.037% MACs, 240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
            "            (1): BatchNorm2d(480, 0.004% Params, 94.08 KMac, 0.008% MACs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            19.36 k, 0.174% Params, 3.79 MMac, 0.333% MACs, \n",
            "            (0): Conv2d(19.2 k, 0.172% Params, 3.76 MMac, 0.331% MACs, 240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, 0.001% Params, 31.36 KMac, 0.003% MACs, 80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (8): InvertedResidual(\n",
            "        34.76 k, 0.312% Params, 6.81 MMac, 0.598% MACs, \n",
            "        (block): Sequential(\n",
            "          34.76 k, 0.312% Params, 6.81 MMac, 0.598% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            16.4 k, 0.147% Params, 3.21 MMac, 0.282% MACs, \n",
            "            (0): Conv2d(16.0 k, 0.144% Params, 3.14 MMac, 0.275% MACs, 80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(400, 0.004% Params, 78.4 KMac, 0.007% MACs, 200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            2.2 k, 0.020% Params, 431.2 KMac, 0.038% MACs, \n",
            "            (0): Conv2d(1.8 k, 0.016% Params, 352.8 KMac, 0.031% MACs, 200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
            "            (1): BatchNorm2d(400, 0.004% Params, 78.4 KMac, 0.007% MACs, 200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            16.16 k, 0.145% Params, 3.17 MMac, 0.278% MACs, \n",
            "            (0): Conv2d(16.0 k, 0.144% Params, 3.14 MMac, 0.275% MACs, 200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, 0.001% Params, 31.36 KMac, 0.003% MACs, 80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (9): InvertedResidual(\n",
            "        31.99 k, 0.287% Params, 6.27 MMac, 0.551% MACs, \n",
            "        (block): Sequential(\n",
            "          31.99 k, 0.287% Params, 6.27 MMac, 0.551% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            15.09 k, 0.135% Params, 2.96 MMac, 0.260% MACs, \n",
            "            (0): Conv2d(14.72 k, 0.132% Params, 2.89 MMac, 0.253% MACs, 80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(368, 0.003% Params, 72.13 KMac, 0.006% MACs, 184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            2.02 k, 0.018% Params, 396.7 KMac, 0.035% MACs, \n",
            "            (0): Conv2d(1.66 k, 0.015% Params, 324.58 KMac, 0.029% MACs, 184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "            (1): BatchNorm2d(368, 0.003% Params, 72.13 KMac, 0.006% MACs, 184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            14.88 k, 0.134% Params, 2.92 MMac, 0.256% MACs, \n",
            "            (0): Conv2d(14.72 k, 0.132% Params, 2.89 MMac, 0.253% MACs, 184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, 0.001% Params, 31.36 KMac, 0.003% MACs, 80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (10): InvertedResidual(\n",
            "        31.99 k, 0.287% Params, 6.27 MMac, 0.551% MACs, \n",
            "        (block): Sequential(\n",
            "          31.99 k, 0.287% Params, 6.27 MMac, 0.551% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            15.09 k, 0.135% Params, 2.96 MMac, 0.260% MACs, \n",
            "            (0): Conv2d(14.72 k, 0.132% Params, 2.89 MMac, 0.253% MACs, 80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(368, 0.003% Params, 72.13 KMac, 0.006% MACs, 184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            2.02 k, 0.018% Params, 396.7 KMac, 0.035% MACs, \n",
            "            (0): Conv2d(1.66 k, 0.015% Params, 324.58 KMac, 0.029% MACs, 184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
            "            (1): BatchNorm2d(368, 0.003% Params, 72.13 KMac, 0.006% MACs, 184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            14.88 k, 0.134% Params, 2.92 MMac, 0.256% MACs, \n",
            "            (0): Conv2d(14.72 k, 0.132% Params, 2.89 MMac, 0.253% MACs, 184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(160, 0.001% Params, 31.36 KMac, 0.003% MACs, 80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (11): InvertedResidual(\n",
            "        214.42 k, 1.925% Params, 19.54 MMac, 1.716% MACs, \n",
            "        (block): Sequential(\n",
            "          214.42 k, 1.925% Params, 19.54 MMac, 1.716% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            39.36 k, 0.353% Params, 7.71 MMac, 0.678% MACs, \n",
            "            (0): Conv2d(38.4 k, 0.345% Params, 7.53 MMac, 0.661% MACs, 80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(960, 0.009% Params, 188.16 KMac, 0.017% MACs, 480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            5.28 k, 0.047% Params, 1.03 MMac, 0.091% MACs, \n",
            "            (0): Conv2d(4.32 k, 0.039% Params, 846.72 KMac, 0.074% MACs, 480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
            "            (1): BatchNorm2d(960, 0.009% Params, 188.16 KMac, 0.017% MACs, 480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            115.8 k, 1.040% Params, 210.0 KMac, 0.018% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 94.08 KMac, 0.008% MACs, output_size=1)\n",
            "            (fc1): Conv2d(57.72 k, 0.518% Params, 57.72 KMac, 0.005% MACs, 480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(58.08 k, 0.521% Params, 58.08 KMac, 0.005% MACs, 120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 120.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            53.98 k, 0.485% Params, 10.58 MMac, 0.929% MACs, \n",
            "            (0): Conv2d(53.76 k, 0.483% Params, 10.54 MMac, 0.925% MACs, 480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(224, 0.002% Params, 43.9 KMac, 0.004% MACs, 112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (12): InvertedResidual(\n",
            "        386.12 k, 3.466% Params, 31.62 MMac, 2.777% MACs, \n",
            "        (block): Sequential(\n",
            "          386.12 k, 3.466% Params, 31.62 MMac, 2.777% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            76.61 k, 0.688% Params, 15.02 MMac, 1.319% MACs, \n",
            "            (0): Conv2d(75.26 k, 0.676% Params, 14.75 MMac, 1.296% MACs, 112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.34 k, 0.012% Params, 263.42 KMac, 0.023% MACs, 672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            7.39 k, 0.066% Params, 1.45 MMac, 0.127% MACs, \n",
            "            (0): Conv2d(6.05 k, 0.054% Params, 1.19 MMac, 0.104% MACs, 672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "            (1): BatchNorm2d(1.34 k, 0.012% Params, 263.42 KMac, 0.023% MACs, 672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            226.63 k, 2.034% Params, 358.51 KMac, 0.031% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 131.71 KMac, 0.012% MACs, output_size=1)\n",
            "            (fc1): Conv2d(113.06 k, 1.015% Params, 113.06 KMac, 0.010% MACs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(113.57 k, 1.019% Params, 113.57 KMac, 0.010% MACs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 168.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            75.49 k, 0.678% Params, 14.8 MMac, 1.299% MACs, \n",
            "            (0): Conv2d(75.26 k, 0.676% Params, 14.75 MMac, 1.296% MACs, 672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(224, 0.002% Params, 43.9 KMac, 0.004% MACs, 112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (13): InvertedResidual(\n",
            "        429.22 k, 3.853% Params, 21.45 MMac, 1.884% MACs, \n",
            "        (block): Sequential(\n",
            "          429.22 k, 3.853% Params, 21.45 MMac, 1.884% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            76.61 k, 0.688% Params, 15.02 MMac, 1.319% MACs, \n",
            "            (0): Conv2d(75.26 k, 0.676% Params, 14.75 MMac, 1.296% MACs, 112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.34 k, 0.012% Params, 263.42 KMac, 0.023% MACs, 672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            18.14 k, 0.163% Params, 889.06 KMac, 0.078% MACs, \n",
            "            (0): Conv2d(16.8 k, 0.151% Params, 823.2 KMac, 0.072% MACs, 672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "            (1): BatchNorm2d(1.34 k, 0.012% Params, 65.86 KMac, 0.006% MACs, 672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            226.63 k, 2.034% Params, 259.73 KMac, 0.023% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 32.93 KMac, 0.003% MACs, output_size=1)\n",
            "            (fc1): Conv2d(113.06 k, 1.015% Params, 113.06 KMac, 0.010% MACs, 672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(113.57 k, 1.019% Params, 113.57 KMac, 0.010% MACs, 168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 168.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            107.84 k, 0.968% Params, 5.28 MMac, 0.464% MACs, \n",
            "            (0): Conv2d(107.52 k, 0.965% Params, 5.27 MMac, 0.463% MACs, 672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, 0.003% Params, 15.68 KMac, 0.001% MACs, 160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (14): InvertedResidual(\n",
            "        797.36 k, 7.158% Params, 16.94 MMac, 1.488% MACs, \n",
            "        (block): Sequential(\n",
            "          797.36 k, 7.158% Params, 16.94 MMac, 1.488% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            155.52 k, 1.396% Params, 7.62 MMac, 0.669% MACs, \n",
            "            (0): Conv2d(153.6 k, 1.379% Params, 7.53 MMac, 0.661% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.017% Params, 94.08 KMac, 0.008% MACs, 960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            25.92 k, 0.233% Params, 1.27 MMac, 0.112% MACs, \n",
            "            (0): Conv2d(24.0 k, 0.215% Params, 1.18 MMac, 0.103% MACs, 960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.017% Params, 94.08 KMac, 0.008% MACs, 960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            462.0 k, 4.147% Params, 509.28 KMac, 0.045% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 47.04 KMac, 0.004% MACs, output_size=1)\n",
            "            (fc1): Conv2d(230.64 k, 2.070% Params, 230.64 KMac, 0.020% MACs, 960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(231.36 k, 2.077% Params, 231.36 KMac, 0.020% MACs, 240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 240.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            153.92 k, 1.382% Params, 7.54 MMac, 0.662% MACs, \n",
            "            (0): Conv2d(153.6 k, 1.379% Params, 7.53 MMac, 0.661% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, 0.003% Params, 15.68 KMac, 0.001% MACs, 160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (15): InvertedResidual(\n",
            "        797.36 k, 7.158% Params, 16.94 MMac, 1.488% MACs, \n",
            "        (block): Sequential(\n",
            "          797.36 k, 7.158% Params, 16.94 MMac, 1.488% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            155.52 k, 1.396% Params, 7.62 MMac, 0.669% MACs, \n",
            "            (0): Conv2d(153.6 k, 1.379% Params, 7.53 MMac, 0.661% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.017% Params, 94.08 KMac, 0.008% MACs, 960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            25.92 k, 0.233% Params, 1.27 MMac, 0.112% MACs, \n",
            "            (0): Conv2d(24.0 k, 0.215% Params, 1.18 MMac, 0.103% MACs, 960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
            "            (1): BatchNorm2d(1.92 k, 0.017% Params, 94.08 KMac, 0.008% MACs, 960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            462.0 k, 4.147% Params, 509.28 KMac, 0.045% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 47.04 KMac, 0.004% MACs, output_size=1)\n",
            "            (fc1): Conv2d(230.64 k, 2.070% Params, 230.64 KMac, 0.020% MACs, 960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(231.36 k, 2.077% Params, 231.36 KMac, 0.020% MACs, 240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 240.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            153.92 k, 1.382% Params, 7.54 MMac, 0.662% MACs, \n",
            "            (0): Conv2d(153.6 k, 1.379% Params, 7.53 MMac, 0.661% MACs, 960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(320, 0.003% Params, 15.68 KMac, 0.001% MACs, 160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (16): Conv2dNormActivation(\n",
            "        155.52 k, 1.396% Params, 7.62 MMac, 0.669% MACs, \n",
            "        (0): Conv2d(153.6 k, 1.379% Params, 7.53 MMac, 0.661% MACs, 160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1.92 k, 0.017% Params, 94.08 KMac, 0.008% MACs, 960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (deeplab): Deeplab(\n",
            "    8.17 M, 73.322% Params, 909.6 MMac, 79.887% MACs, \n",
            "    (aspp): ASPP(\n",
            "      7.46 M, 66.960% Params, 353.78 MMac, 31.072% MACs, \n",
            "      (act): ReLU6(0, 0.000% Params, 62.98 KMac, 0.006% MACs, )\n",
            "      (bn_1): BatchNorm2d(512, 0.005% Params, 25.09 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_2): BatchNorm2d(512, 0.005% Params, 25.09 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_3): BatchNorm2d(512, 0.005% Params, 25.09 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_4): BatchNorm2d(512, 0.005% Params, 25.09 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_5): BatchNorm2d(512, 0.005% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_6): BatchNorm2d(512, 0.005% Params, 25.09 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (operation_1): Conv2d(246.02 k, 2.208% Params, 12.05 MMac, 1.059% MACs, 960, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (operation_2): Conv2d(2.21 M, 19.857% Params, 108.39 MMac, 9.520% MACs, 960, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "      (operation_3): Conv2d(2.21 M, 19.857% Params, 108.39 MMac, 9.520% MACs, 960, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
            "      (operation_4): Conv2d(2.21 M, 19.857% Params, 108.39 MMac, 9.520% MACs, 960, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
            "      (pool): AdaptiveAvgPool2d(0, 0.000% Params, 47.04 KMac, 0.004% MACs, output_size=1)\n",
            "      (conv_pool): Conv2d(246.02 k, 2.208% Params, 246.02 KMac, 0.022% MACs, 960, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv): Conv2d(327.94 k, 2.944% Params, 16.07 MMac, 1.411% MACs, 1280, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (low_conv): Conv2d(1.97 k, 0.018% Params, 1.54 MMac, 0.136% MACs, 40, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (low_bn): BatchNorm2d(96, 0.001% Params, 75.26 KMac, 0.007% MACs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (act): ReLU6(0, 0.000% Params, 37.63 KMac, 0.003% MACs, )\n",
            "    (classifier): Sequential(\n",
            "      706.58 k, 6.343% Params, 554.16 MMac, 48.670% MACs, \n",
            "      (0): Conv2d(700.67 k, 6.290% Params, 549.33 MMac, 48.245% MACs, 304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, 0.005% Params, 401.41 KMac, 0.035% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(0, 0.000% Params, 200.7 KMac, 0.018% MACs, inplace=True)\n",
            "      (3): Conv2d(5.4 k, 0.048% Params, 4.23 MMac, 0.372% MACs, 256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Computational complexity:       1.14 GMac\n",
            "Number of parameters:           11.14 M \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from ptflops import get_model_complexity_info\n",
        "\n",
        "model = SegmentationCustom(num_classes=21, output_stride=16, model_name='mobilenet_v3_small')\n",
        "\n",
        "# Set input resolution (adjust as needed)\n",
        "input_res = (3, 224, 224)\n",
        "\n",
        "# Calculate FLOPs and parameters\n",
        "macs, params = get_model_complexity_info(model, input_res, as_strings=True,\n",
        "                                           print_per_layer_stat=True, verbose=True)\n",
        "\n",
        "print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
        "print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fURG0lKvuUcw",
        "outputId": "11a8b303-dd91-4494-99a7-86b5b0de784a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: module Hardswish is treated as a zero-op.\n",
            "Warning: module Conv2dNormActivation is treated as a zero-op.\n",
            "Warning: module Hardsigmoid is treated as a zero-op.\n",
            "Warning: module SqueezeExcitation is treated as a zero-op.\n",
            "Warning: module InvertedResidual is treated as a zero-op.\n",
            "Warning: module IntermediateLayerGetter is treated as a zero-op.\n",
            "Warning: module ASPP is treated as a zero-op.\n",
            "Warning: module Deeplab is treated as a zero-op.\n",
            "Warning: module SegmentationCustom is treated as a zero-op.\n",
            "SegmentationCustom(\n",
            "  6.24 M, 100.000% Params, 832.49 MMac, 99.876% MACs, \n",
            "  (feature_extractor): IntermediateLayerGetter(\n",
            "    927.01 k, 14.848% Params, 58.48 MMac, 7.016% MACs, \n",
            "    (low_level_features): Sequential(\n",
            "      10.49 k, 0.168% Params, 18.12 MMac, 2.174% MACs, \n",
            "      (0): Conv2dNormActivation(\n",
            "        464, 0.007% Params, 5.82 MMac, 0.698% MACs, \n",
            "        (0): Conv2d(432, 0.007% Params, 5.42 MMac, 0.650% MACs, 3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(32, 0.001% Params, 401.41 KMac, 0.048% MACs, 16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "      )\n",
            "      (1): InvertedResidual(\n",
            "        744, 0.012% Params, 1.56 MMac, 0.187% MACs, \n",
            "        (block): Sequential(\n",
            "          744, 0.012% Params, 1.56 MMac, 0.187% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            176, 0.003% Params, 602.11 KMac, 0.072% MACs, \n",
            "            (0): Conv2d(144, 0.002% Params, 451.58 KMac, 0.054% MACs, 16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
            "            (1): BatchNorm2d(32, 0.001% Params, 100.35 KMac, 0.012% MACs, 16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 50.18 KMac, 0.006% MACs, inplace=True)\n",
            "          )\n",
            "          (1): SqueezeExcitation(\n",
            "            280, 0.004% Params, 50.46 KMac, 0.006% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 50.18 KMac, 0.006% MACs, output_size=1)\n",
            "            (fc1): Conv2d(136, 0.002% Params, 136.0 Mac, 0.000% MACs, 16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(144, 0.002% Params, 144.0 Mac, 0.000% MACs, 8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 8.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            288, 0.005% Params, 903.17 KMac, 0.108% MACs, \n",
            "            (0): Conv2d(256, 0.004% Params, 802.82 KMac, 0.096% MACs, 16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(32, 0.001% Params, 100.35 KMac, 0.012% MACs, 16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): InvertedResidual(\n",
            "        3.86 k, 0.062% Params, 6.36 MMac, 0.763% MACs, \n",
            "        (block): Sequential(\n",
            "          3.86 k, 0.062% Params, 6.36 MMac, 0.763% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            1.3 k, 0.021% Params, 4.29 MMac, 0.515% MACs, \n",
            "            (0): Conv2d(1.15 k, 0.018% Params, 3.61 MMac, 0.433% MACs, 16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(144, 0.002% Params, 451.58 KMac, 0.054% MACs, 72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 225.79 KMac, 0.027% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            792, 0.013% Params, 677.38 KMac, 0.081% MACs, \n",
            "            (0): Conv2d(648, 0.010% Params, 508.03 KMac, 0.061% MACs, 72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
            "            (1): BatchNorm2d(144, 0.002% Params, 112.9 KMac, 0.014% MACs, 72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 56.45 KMac, 0.007% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            1.78 k, 0.028% Params, 1.39 MMac, 0.167% MACs, \n",
            "            (0): Conv2d(1.73 k, 0.028% Params, 1.35 MMac, 0.163% MACs, 72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, 0.001% Params, 37.63 KMac, 0.005% MACs, 24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): InvertedResidual(\n",
            "        5.42 k, 0.087% Params, 4.38 MMac, 0.526% MACs, \n",
            "        (block): Sequential(\n",
            "          5.42 k, 0.087% Params, 4.38 MMac, 0.526% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            2.29 k, 0.037% Params, 1.86 MMac, 0.223% MACs, \n",
            "            (0): Conv2d(2.11 k, 0.034% Params, 1.66 MMac, 0.199% MACs, 24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(176, 0.003% Params, 137.98 KMac, 0.017% MACs, 88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 68.99 KMac, 0.008% MACs, inplace=True)\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            968, 0.016% Params, 827.9 KMac, 0.099% MACs, \n",
            "            (0): Conv2d(792, 0.013% Params, 620.93 KMac, 0.074% MACs, 88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
            "            (1): BatchNorm2d(176, 0.003% Params, 137.98 KMac, 0.017% MACs, 88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(0, 0.000% Params, 68.99 KMac, 0.008% MACs, inplace=True)\n",
            "          )\n",
            "          (2): Conv2dNormActivation(\n",
            "            2.16 k, 0.035% Params, 1.69 MMac, 0.203% MACs, \n",
            "            (0): Conv2d(2.11 k, 0.034% Params, 1.66 MMac, 0.199% MACs, 88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(48, 0.001% Params, 37.63 KMac, 0.005% MACs, 24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (high_level_features): Sequential(\n",
            "      916.52 k, 14.680% Params, 40.36 MMac, 4.842% MACs, \n",
            "      (4): InvertedResidual(\n",
            "        13.74 k, 0.220% Params, 3.26 MMac, 0.391% MACs, \n",
            "        (block): Sequential(\n",
            "          13.74 k, 0.220% Params, 3.26 MMac, 0.391% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            2.5 k, 0.040% Params, 1.96 MMac, 0.235% MACs, \n",
            "            (0): Conv2d(2.3 k, 0.037% Params, 1.81 MMac, 0.217% MACs, 24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, 0.003% Params, 150.53 KMac, 0.018% MACs, 96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            2.59 k, 0.042% Params, 508.03 KMac, 0.061% MACs, \n",
            "            (0): Conv2d(2.4 k, 0.038% Params, 470.4 KMac, 0.056% MACs, 96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
            "            (1): BatchNorm2d(192, 0.003% Params, 37.63 KMac, 0.005% MACs, 96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            4.73 k, 0.076% Params, 23.57 KMac, 0.003% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 18.82 KMac, 0.002% MACs, output_size=1)\n",
            "            (fc1): Conv2d(2.33 k, 0.037% Params, 2.33 KMac, 0.000% MACs, 96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(2.4 k, 0.038% Params, 2.4 KMac, 0.000% MACs, 24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 24.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            3.92 k, 0.063% Params, 768.32 KMac, 0.092% MACs, \n",
            "            (0): Conv2d(3.84 k, 0.062% Params, 752.64 KMac, 0.090% MACs, 96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, 0.001% Params, 15.68 KMac, 0.002% MACs, 40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): InvertedResidual(\n",
            "        57.26 k, 0.917% Params, 5.22 MMac, 0.626% MACs, \n",
            "        (block): Sequential(\n",
            "          57.26 k, 0.917% Params, 5.22 MMac, 0.626% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            10.08 k, 0.161% Params, 1.98 MMac, 0.237% MACs, \n",
            "            (0): Conv2d(9.6 k, 0.154% Params, 1.88 MMac, 0.226% MACs, 40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(480, 0.008% Params, 94.08 KMac, 0.011% MACs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            6.48 k, 0.104% Params, 1.27 MMac, 0.152% MACs, \n",
            "            (0): Conv2d(6.0 k, 0.096% Params, 1.18 MMac, 0.141% MACs, 240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "            (1): BatchNorm2d(480, 0.008% Params, 94.08 KMac, 0.011% MACs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            31.02 k, 0.497% Params, 78.13 KMac, 0.009% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 47.04 KMac, 0.006% MACs, output_size=1)\n",
            "            (fc1): Conv2d(15.42 k, 0.247% Params, 15.42 KMac, 0.002% MACs, 240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(15.6 k, 0.250% Params, 15.6 KMac, 0.002% MACs, 64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 64.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            9.68 k, 0.155% Params, 1.9 MMac, 0.228% MACs, \n",
            "            (0): Conv2d(9.6 k, 0.154% Params, 1.88 MMac, 0.226% MACs, 240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, 0.001% Params, 15.68 KMac, 0.002% MACs, 40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (6): InvertedResidual(\n",
            "        57.26 k, 0.917% Params, 5.22 MMac, 0.626% MACs, \n",
            "        (block): Sequential(\n",
            "          57.26 k, 0.917% Params, 5.22 MMac, 0.626% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            10.08 k, 0.161% Params, 1.98 MMac, 0.237% MACs, \n",
            "            (0): Conv2d(9.6 k, 0.154% Params, 1.88 MMac, 0.226% MACs, 40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(480, 0.008% Params, 94.08 KMac, 0.011% MACs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            6.48 k, 0.104% Params, 1.27 MMac, 0.152% MACs, \n",
            "            (0): Conv2d(6.0 k, 0.096% Params, 1.18 MMac, 0.141% MACs, 240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
            "            (1): BatchNorm2d(480, 0.008% Params, 94.08 KMac, 0.011% MACs, 240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            31.02 k, 0.497% Params, 78.13 KMac, 0.009% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 47.04 KMac, 0.006% MACs, output_size=1)\n",
            "            (fc1): Conv2d(15.42 k, 0.247% Params, 15.42 KMac, 0.002% MACs, 240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(15.6 k, 0.250% Params, 15.6 KMac, 0.002% MACs, 64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 64.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            9.68 k, 0.155% Params, 1.9 MMac, 0.228% MACs, \n",
            "            (0): Conv2d(9.6 k, 0.154% Params, 1.88 MMac, 0.226% MACs, 240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(80, 0.001% Params, 15.68 KMac, 0.002% MACs, 40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (7): InvertedResidual(\n",
            "        21.97 k, 0.352% Params, 2.8 MMac, 0.336% MACs, \n",
            "        (block): Sequential(\n",
            "          21.97 k, 0.352% Params, 2.8 MMac, 0.336% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            5.04 k, 0.081% Params, 987.84 KMac, 0.119% MACs, \n",
            "            (0): Conv2d(4.8 k, 0.077% Params, 940.8 KMac, 0.113% MACs, 40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(240, 0.004% Params, 47.04 KMac, 0.006% MACs, 120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            3.24 k, 0.052% Params, 635.04 KMac, 0.076% MACs, \n",
            "            (0): Conv2d(3.0 k, 0.048% Params, 588.0 KMac, 0.071% MACs, 120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
            "            (1): BatchNorm2d(240, 0.004% Params, 47.04 KMac, 0.006% MACs, 120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            7.83 k, 0.125% Params, 31.38 KMac, 0.004% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 23.52 KMac, 0.003% MACs, output_size=1)\n",
            "            (fc1): Conv2d(3.87 k, 0.062% Params, 3.87 KMac, 0.000% MACs, 120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(3.96 k, 0.063% Params, 3.96 KMac, 0.000% MACs, 32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 32.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            5.86 k, 0.094% Params, 1.15 MMac, 0.138% MACs, \n",
            "            (0): Conv2d(5.76 k, 0.092% Params, 1.13 MMac, 0.135% MACs, 120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(96, 0.002% Params, 18.82 KMac, 0.002% MACs, 48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (8): InvertedResidual(\n",
            "        29.8 k, 0.477% Params, 3.59 MMac, 0.430% MACs, \n",
            "        (block): Sequential(\n",
            "          29.8 k, 0.477% Params, 3.59 MMac, 0.430% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            7.2 k, 0.115% Params, 1.41 MMac, 0.169% MACs, \n",
            "            (0): Conv2d(6.91 k, 0.111% Params, 1.35 MMac, 0.163% MACs, 48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(288, 0.005% Params, 56.45 KMac, 0.007% MACs, 144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            3.89 k, 0.062% Params, 762.05 KMac, 0.091% MACs, \n",
            "            (0): Conv2d(3.6 k, 0.058% Params, 705.6 KMac, 0.085% MACs, 144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
            "            (1): BatchNorm2d(288, 0.005% Params, 56.45 KMac, 0.007% MACs, 144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            11.7 k, 0.187% Params, 39.97 KMac, 0.005% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 28.22 KMac, 0.003% MACs, output_size=1)\n",
            "            (fc1): Conv2d(5.8 k, 0.093% Params, 5.8 KMac, 0.001% MACs, 144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(5.9 k, 0.095% Params, 5.9 KMac, 0.001% MACs, 40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 40.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            7.01 k, 0.112% Params, 1.37 MMac, 0.165% MACs, \n",
            "            (0): Conv2d(6.91 k, 0.111% Params, 1.35 MMac, 0.163% MACs, 144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(96, 0.002% Params, 18.82 KMac, 0.002% MACs, 48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (9): InvertedResidual(\n",
            "        91.85 k, 1.471% Params, 4.62 MMac, 0.555% MACs, \n",
            "        (block): Sequential(\n",
            "          91.85 k, 1.471% Params, 4.62 MMac, 0.555% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            14.4 k, 0.231% Params, 2.82 MMac, 0.339% MACs, \n",
            "            (0): Conv2d(13.82 k, 0.221% Params, 2.71 MMac, 0.325% MACs, 48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(576, 0.009% Params, 112.9 KMac, 0.014% MACs, 288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            7.78 k, 0.125% Params, 381.02 KMac, 0.046% MACs, \n",
            "            (0): Conv2d(7.2 k, 0.115% Params, 352.8 KMac, 0.042% MACs, 288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
            "            (1): BatchNorm2d(576, 0.009% Params, 28.22 KMac, 0.003% MACs, 288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            41.83 k, 0.670% Params, 56.02 KMac, 0.007% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 14.11 KMac, 0.002% MACs, output_size=1)\n",
            "            (fc1): Conv2d(20.81 k, 0.333% Params, 20.81 KMac, 0.002% MACs, 288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(21.02 k, 0.337% Params, 21.02 KMac, 0.003% MACs, 72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 72.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            27.84 k, 0.446% Params, 1.36 MMac, 0.164% MACs, \n",
            "            (0): Conv2d(27.65 k, 0.443% Params, 1.35 MMac, 0.163% MACs, 288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, 0.003% Params, 9.41 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (10): InvertedResidual(\n",
            "        294.1 k, 4.711% Params, 6.44 MMac, 0.773% MACs, \n",
            "        (block): Sequential(\n",
            "          294.1 k, 4.711% Params, 6.44 MMac, 0.773% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            56.45 k, 0.904% Params, 2.77 MMac, 0.332% MACs, \n",
            "            (0): Conv2d(55.3 k, 0.886% Params, 2.71 MMac, 0.325% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.018% Params, 56.45 KMac, 0.007% MACs, 576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            15.55 k, 0.249% Params, 762.05 KMac, 0.091% MACs, \n",
            "            (0): Conv2d(14.4 k, 0.231% Params, 705.6 KMac, 0.085% MACs, 576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.018% Params, 56.45 KMac, 0.007% MACs, 576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            166.61 k, 2.669% Params, 194.98 KMac, 0.023% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 28.22 KMac, 0.003% MACs, output_size=1)\n",
            "            (fc1): Conv2d(83.09 k, 1.331% Params, 83.09 KMac, 0.010% MACs, 576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(83.52 k, 1.338% Params, 83.52 KMac, 0.010% MACs, 144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 144.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            55.49 k, 0.889% Params, 2.72 MMac, 0.326% MACs, \n",
            "            (0): Conv2d(55.3 k, 0.886% Params, 2.71 MMac, 0.325% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, 0.003% Params, 9.41 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (11): InvertedResidual(\n",
            "        294.1 k, 4.711% Params, 6.44 MMac, 0.773% MACs, \n",
            "        (block): Sequential(\n",
            "          294.1 k, 4.711% Params, 6.44 MMac, 0.773% MACs, \n",
            "          (0): Conv2dNormActivation(\n",
            "            56.45 k, 0.904% Params, 2.77 MMac, 0.332% MACs, \n",
            "            (0): Conv2d(55.3 k, 0.886% Params, 2.71 MMac, 0.325% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.018% Params, 56.45 KMac, 0.007% MACs, 576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (1): Conv2dNormActivation(\n",
            "            15.55 k, 0.249% Params, 762.05 KMac, 0.091% MACs, \n",
            "            (0): Conv2d(14.4 k, 0.231% Params, 705.6 KMac, 0.085% MACs, 576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
            "            (1): BatchNorm2d(1.15 k, 0.018% Params, 56.45 KMac, 0.007% MACs, 576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "            (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (2): SqueezeExcitation(\n",
            "            166.61 k, 2.669% Params, 194.98 KMac, 0.023% MACs, \n",
            "            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 28.22 KMac, 0.003% MACs, output_size=1)\n",
            "            (fc1): Conv2d(83.09 k, 1.331% Params, 83.09 KMac, 0.010% MACs, 576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (fc2): Conv2d(83.52 k, 1.338% Params, 83.52 KMac, 0.010% MACs, 144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (activation): ReLU(0, 0.000% Params, 144.0 Mac, 0.000% MACs, )\n",
            "            (scale_activation): Hardsigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "          )\n",
            "          (3): Conv2dNormActivation(\n",
            "            55.49 k, 0.889% Params, 2.72 MMac, 0.326% MACs, \n",
            "            (0): Conv2d(55.3 k, 0.886% Params, 2.71 MMac, 0.325% MACs, 576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(192, 0.003% Params, 9.41 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (12): Conv2dNormActivation(\n",
            "        56.45 k, 0.904% Params, 2.77 MMac, 0.332% MACs, \n",
            "        (0): Conv2d(55.3 k, 0.886% Params, 2.71 MMac, 0.325% MACs, 96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1.15 k, 0.018% Params, 56.45 KMac, 0.007% MACs, 576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
            "        (2): Hardswish(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (deeplab): Deeplab(\n",
            "    5.32 M, 85.152% Params, 774.01 MMac, 92.860% MACs, \n",
            "    (aspp): ASPP(\n",
            "      4.61 M, 73.814% Params, 218.79 MMac, 26.249% MACs, \n",
            "      (act): ReLU6(0, 0.000% Params, 62.98 KMac, 0.008% MACs, )\n",
            "      (bn_1): BatchNorm2d(512, 0.008% Params, 25.09 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_2): BatchNorm2d(512, 0.008% Params, 25.09 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_3): BatchNorm2d(512, 0.008% Params, 25.09 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_4): BatchNorm2d(512, 0.008% Params, 25.09 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_5): BatchNorm2d(512, 0.008% Params, 512.0 Mac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (bn_6): BatchNorm2d(512, 0.008% Params, 25.09 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (operation_1): Conv2d(147.71 k, 2.366% Params, 7.24 MMac, 0.868% MACs, 576, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (operation_2): Conv2d(1.33 M, 21.260% Params, 65.04 MMac, 7.803% MACs, 576, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "      (operation_3): Conv2d(1.33 M, 21.260% Params, 65.04 MMac, 7.803% MACs, 576, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
            "      (operation_4): Conv2d(1.33 M, 21.260% Params, 65.04 MMac, 7.803% MACs, 576, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
            "      (pool): AdaptiveAvgPool2d(0, 0.000% Params, 28.22 KMac, 0.003% MACs, output_size=1)\n",
            "      (conv_pool): Conv2d(147.71 k, 2.366% Params, 147.71 KMac, 0.018% MACs, 576, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv): Conv2d(327.94 k, 5.253% Params, 16.07 MMac, 1.928% MACs, 1280, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (low_conv): Conv2d(1.2 k, 0.019% Params, 940.8 KMac, 0.113% MACs, 24, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (low_bn): BatchNorm2d(96, 0.002% Params, 75.26 KMac, 0.009% MACs, 48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (act): ReLU6(0, 0.000% Params, 37.63 KMac, 0.005% MACs, )\n",
            "    (classifier): Sequential(\n",
            "      706.58 k, 11.317% Params, 554.16 MMac, 66.484% MACs, \n",
            "      (0): Conv2d(700.67 k, 11.223% Params, 549.33 MMac, 65.904% MACs, 304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, 0.008% Params, 401.41 KMac, 0.048% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(0, 0.000% Params, 200.7 KMac, 0.024% MACs, inplace=True)\n",
            "      (3): Conv2d(5.4 k, 0.086% Params, 4.23 MMac, 0.508% MACs, 256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Computational complexity:       833.53 MMac\n",
            "Number of parameters:           6.24 M  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}